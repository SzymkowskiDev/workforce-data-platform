{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "jobs = pd.read_csv('C:\\Projects\\workforce-data-platform\\wdp\\employee_advisor\\data\\job_offers.csv')\n",
    "# jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TITLE\n",
    "\n",
    "# get counts of each job title and convert to DataFrame\n",
    "title_counts = jobs['title'].value_counts().reset_index()\n",
    "\n",
    "# rename columns and sort by count descending\n",
    "title_counts.columns = ['title', 'count']\n",
    "title_counts = title_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# save job title counts to CSV file\n",
    "title_counts.to_csv('job_title_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKILLS\n",
    "\n",
    "# generate list of columns to check based on columns with data type int64\n",
    "cols_to_check = list(jobs.select_dtypes(include=['int64']).columns[jobs.select_dtypes(include=['int64']).apply(lambda x: x.nunique() == 2)])\n",
    "\n",
    "# get count of 1's in each column and create summary DataFrame\n",
    "summary_df = pd.DataFrame({'column_name': cols_to_check,\n",
    "                           'count': jobs[cols_to_check].sum()}).sort_values(by='count', ascending=False)\n",
    "\n",
    "# save summary DataFrame to CSV file\n",
    "summary_df.to_csv('skill_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENIORTIY\n",
    "\n",
    "# create a summary DataFrame\n",
    "summary_df = pd.DataFrame(jobs['experience_level'].value_counts())\n",
    "\n",
    "# reset the index and rename the columns\n",
    "summary_df.reset_index(inplace=True)\n",
    "summary_df.rename(columns={'index': 'experience_level', 'experience_level': 'count'}, inplace=True)\n",
    "\n",
    "# sort by count in descending order\n",
    "summary_df.sort_values(by='count', ascending=False, inplace=True)\n",
    "\n",
    "# save the summary DataFrame as a CSV file\n",
    "summary_df.to_csv('experience_level_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMPLOYERS\n",
    "\n",
    "# get counts of each job title and convert to DataFrame\n",
    "company_counts = jobs['company_name'].value_counts().reset_index()\n",
    "\n",
    "# rename columns and sort by count descending\n",
    "company_counts.columns = ['company', 'count']\n",
    "company_counts = company_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# save job title counts to CSV file\n",
    "company_counts.to_csv('company_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIELDS\n",
    "\n",
    "# Compute the count of each marker_icon value\n",
    "count_series = jobs['marker_icon'].value_counts()\n",
    "\n",
    "# Create a new dataframe with marker_icon and count columns\n",
    "field_counts = pd.DataFrame({'marker_icon': count_series.index, 'count': count_series.values})\n",
    "\n",
    "# Save the new dataframe as a CSV file\n",
    "field_counts.to_csv('field_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKILLS DISTRIBUTION\n",
    "skill_counts = pd.read_csv('C:\\Projects\\workforce-data-platform\\wdp\\employee_advisor\\data\\skill_counts.csv')\n",
    "\n",
    "# Sort the data by count in descending order\n",
    "skill_counts = skill_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Create a vertical line plot of the counts for all skills\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(skill_counts['count'], marker='o')\n",
    "\n",
    "# Set the x and y labels, and the title of the plot\n",
    "plt.xlabel('Skill')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Skills')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIELD COUNTS\n",
    "\n",
    "field_counts = pd.read_csv('C:\\Projects\\workforce-data-platform\\wdp\\employee_advisor\\data\\\\field_counts2.csv')\n",
    "\n",
    "# Sort the data by count in descending order and select the top 50 rows\n",
    "top_fields = field_counts.sort_values(by='count', ascending=False).head(50)\n",
    "\n",
    "# Reverse the order of the rows so that the largest counts are at the top\n",
    "top_fields = top_fields.iloc[::-1]\n",
    "\n",
    "# Create the horizontal bar chart using matplotlib\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.barh(y=top_fields['field'], width=top_fields['count'], height=0.4)\n",
    "\n",
    "# Add the count as a text label at the end of each bar\n",
    "for i, count in enumerate(top_fields['count']):\n",
    "    plt.text(count + 10, i, str(count), ha='left', va='center')\n",
    "\n",
    "# Set the x and y labels, and the title of the plot\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Field')\n",
    "plt.title('Distribution of Top Fields')\n",
    "\n",
    "# Adjust the spacing between the bars\n",
    "plt.yticks(np.arange(len(top_fields)), top_fields['field'])\n",
    "plt.subplots_adjust(left=0.0025)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALARY\n",
    "jobs = pd.read_csv('C:\\Projects\\workforce-data-platform\\wdp\\employee_advisor\\data\\job_offers.csv')\n",
    "\n",
    "# Count the number of missing values in the 'mid_point_pln' column of the 'jobs' dataframe\n",
    "# num_missing = jobs['mid_point_pln'].isna().sum()\n",
    "# print(\"Number of missing values in 'mid_point_pln':\", num_missing)\n",
    "# 3635\n",
    "\n",
    "# remove missing values\n",
    "jobs = jobs.dropna(subset=['currency'])\n",
    "\n",
    "# remove jobs outside Poland\n",
    "jobs = jobs[jobs['country_code'] == 'PL']\n",
    "\n",
    "# create a dictionary to map currencies to conversion factors\n",
    "currency_factors = {'pln': 1, 'chf': 4.70, 'eur': 4.67, 'gbp': 5.32, 'usd': 4.29}\n",
    "\n",
    "# Apply currency conversion to salary columns\n",
    "jobs['salary_from_pln'] = jobs.apply(lambda x: x['salary_from']*currency_factors.get(x['currency'], 1), axis=1)\n",
    "jobs['salary_to_pln'] = jobs.apply(lambda x: x['salary_to']*currency_factors.get(x['currency'], 1), axis=1)    \n",
    "\n",
    "# create a new column to hold the mid point salary in PLN\n",
    "jobs['midpoint_pln'] = jobs.apply(lambda x: (x['salary_from']*currency_factors.get(x['currency'], 1) \n",
    "                                               + x['salary_to']*currency_factors.get(x['currency'], 1))/2, axis=1)\n",
    "\n",
    "# SALARY BY EXPERIENCE (pesymistic, optimistic, midpoint): experience_level\n",
    "def summarize_dataframe(df, group_col, value_col, output_file):\n",
    "    # Group the DataFrame by the specified column and calculate summary statistics\n",
    "    grouped_df = df.groupby(group_col)[value_col].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "\n",
    "    # Rename the columns to include the value column name\n",
    "    new_cols = [f'{col}_{value_col}' for col in grouped_df.columns]\n",
    "    grouped_df.columns = new_cols\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    grouped_df.to_csv(output_file)\n",
    "\n",
    "summarize_dataframe(jobs, 'experience_level', 'salary_from_pln', 'salary_by_experience.csv')\n",
    "\n",
    "\n",
    "# SALARY BY FIELD (pesymistic, optimistic, midpoint): marker_icon\n",
    "summarize_dataframe(jobs, 'marker_icon', 'salary_from_pln', 'salary_by_field.csv')\n",
    "\n",
    "\n",
    "# SALARY BY CITY (pesymistic, optimistic, midpoint): city\n",
    "summarize_dataframe(jobs, 'city', 'salary_from_pln', 'salary_by_city.csv')\n",
    "\n",
    "\n",
    "# SALARY BY COMPANY (pesymistic, optimistic, midpoint): company_name\n",
    "summarize_dataframe(jobs, 'company_name', 'salary_from_pln', 'salary_by_company.csv')\n",
    "\n",
    "\n",
    "# SALARY BY COMPANY (pesymistic, optimistic, midpoint): company_size\n",
    "summarize_dataframe(jobs, 'company_size', 'salary_from_pln', 'salary_by_company_size.csv')\n",
    "\n",
    "\n",
    "# SALARY BY SKILL (pesymistic, optimistic, midpoint): list of first 50 most popular skills\n",
    "summarize_dataframe(jobs, 'company_size', 'salary_from_pln', 'salary_by_skill_.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
